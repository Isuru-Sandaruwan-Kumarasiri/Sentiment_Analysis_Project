{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003b893d-869f-41ee-b77c-5e7c0cf34eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b1a3cb-d955-4b2d-9faf-f379979fcd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_functuations (text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation,'')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff808e81-3837-4967-876b-bc728c999c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isuru Sandaruwan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../static/model/model.pickle','rb') as f:\n",
    "    model =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec4249f-e611-4a7d-a235-e12e433dae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english','r') as file :\n",
    "    sw =file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8300310f-356c-471c-b5d4-c0973c92cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocabulary(features)\n",
    "\n",
    "vocab= pd.read_csv('../static/model/vocabulary.txt',header=None)\n",
    "tokens =vocab[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e2adecc-088e-4647-99b4-5b86ef121715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6fd7dff-4d27-49c4-a6b4-2d9d0ffed994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(text):\n",
    "    data=pd.DataFrame([text],columns=['tweet'])\n",
    "\n",
    "    data[\"tweet\"]=data[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    \n",
    "    data[\"tweet\"]=data[\"tweet\"].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',x,flags=re.MULTILINE) for x in x.split()))\n",
    "    data[\"tweet\"]=data[\"tweet\"].apply(remove_functuations)\n",
    "    \n",
    "    data[\"tweet\"] = data[\"tweet\"].str.replace(r'\\d+', '', regex=True)\n",
    "    \n",
    "    data[\"tweet\"]=data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "    \n",
    "    data[\"tweet\"]=data[\"tweet\"].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))\n",
    "\n",
    "    return data[\"tweet\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ebd795-3ed6-4cec-be26-8c6a903d60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizar(ds,vocabulary) :\n",
    "    vectorized_list =[]\n",
    "\n",
    "    for sentence in ds :\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "\n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] =1\n",
    "\n",
    "        vectorized_list.append((sentence_lst))\n",
    "    vectorized_lst_new =np.asarray(vectorized_list,dtype=np.float32)\n",
    "    return vectorized_lst_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9a713e-c062-4476-b09c-0c1d96511f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vectorized_text) :\n",
    "    prediction =model.predict(vectorized_text)\n",
    "    if prediction ==1 :\n",
    "        return 'negative'\n",
    "    else :\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1336edbc-64cd-48dc-b5d5-178348929bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \"excellent and love it\"\n",
    "pre_processed_text=preprocessing(text)\n",
    "vectorized_text=vectorizar(pre_processed_text,tokens)\n",
    "prediction=get_prediction(vectorized_text)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
